vagrant 배포 서버를 사용한 vultr 클라우드 vm에 kubernetes 배포
====
### 배포환경
- **03.** 에서 구축한 kubespray 배포용 vagrant vm을 활용하여 배포
- target 서버 1대로 master & worker
- root 외부 접근 가능
- 111.111.111.111 ip를 실 서버 주소로 치환 하여 진행

### 1. 배포 서버 접속
root에서 진행
```
C:\vagrant\kubespray>vagrant up
...
C:\vagrant\kubespray>vagrant ssh
$ su -
```

### 2. SSH 등록
```
ssh-copy-id root@111.111.111.111
```

### 3. 배포 설정 복사
```
# cd kubespray
# cp -rfp ./inventory/sample ./inventory/vultrvm
# cp /vagrant/vultrvm/hosts.yaml ./inventory/vultrvm/hosts.yaml
# cp /vagrant/vultrvm/addons.yml ./inventory/vultrvm/group_vars/k8s_cluster/addons.yml
```

#### 3-1. hosts.yaml
```yaml
all:
  hosts:
    nkcserver:
      ansible_host: 111.111.111.111
      ip: 111.111.111.111
      access_ip: 111.111.111.111
  children:
    kube_control_plane:
      hosts:
        nkcserver:
    kube_node:
      hosts:
        nkcserver:
    etcd:
      hosts:
        nkcserver:
    k8s_cluster:
      children:
        kube_control_plane:
        kube_node:
    calico_rr:
      hosts: {}
```

#### 3.2 addons.yml
- **03.** 과 동일

### 4. target 서버 접속 확인
```
# ansible all -i inventory/vultrvm/hosts.yaml -m ping
nkcserver | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
```

### 5. 배포
```
# ansible-playbook -i inventory/vultrvm/hosts.yaml --private-key /root/.ssh/id_rsa --become --become-user=root cluster.yml
...
PLAY RECAP *************************************************************************************************************
localhost                  : ok=4    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
nkcserver                  : ok=674  changed=133  unreachable=0    failed=0    skipped=1200 rescued=0    ignored=2
```

### 6. 배포 확인(master 서버에서 실행)
root 유저로 확인하였음(~/.kube/config 생성 skip)
```
# kubectl cluster-info
Kubernetes control plane is running at https://127.0.0.1:6443

s# kubectl get nodes -o wide
NAME        STATUS   ROLES                  AGE   VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME
nkcserver   Ready    control-plane,master   48m   v1.21.3   111.111.111.111   <none>        Ubuntu 20.04.2 LTS   5.4.0-73-generic   docker://20.10.7
```

### 기타 이슈
- Kubespray에서 접속을 위해 사용한 Public IP가 INTERNAL-IP에 지정됨.
- IP 변경을 위해서는 1) kubelet config option 변경(--node-ip) 혹은, 2) target 서버의 내부망에서 접근 통한 배포 필요.
- Question : https://serverfault.com/questions/1006989/how-to-change-the-k8s-internal-ip-addresses
- Solution : https://medium.com/@kanrangsan/how-to-specify-internal-ip-for-kubernetes-worker-node-24790b2884fd

### Kubespray를 활용한 Production 환경 배포에 관하여,
- 배포툴을 사용하는데 배포를 완료하기 위해 추가적인 설정을 해주어야 한다면, 배포 툴을 사용하는 의미가 없음.
- 배포툴 사용을 위한 추가 학습이 필요하다면, 차라리 직접 설치 및 배포 하는것이 오히려 더 빠르고 운영 노하우 습득 관점에서 이익이 될 수도 있음.
- 이 뿐만 아니라, 폐쇄망 내 설치를 위한 환경 구성(내부 repo 구성, static file 셋업, ...)에 들어갈 수고를 생각해 보아도 이는 회의적.
> https://github.com/kubernetes-sigs/kubespray/blob/master/docs/offline-environment.md
- 배포 툴 사용이 만능이 아닌 관계로, Manual setup을 통한 Kubernetes Cluster 구성 방법 학습 필요.(+ RHEL7 사용)
> https://kubetm.github.io/k8s/92-installation/case4/
